---
#
# THIS IS A DEMO CONFIGURATION MOSTLY FOR TESTING
#

# *_managed vars denote whether ansible takes care of the application or not.
#   `X_managed: false` application will still fire if it is in `Y_managed: true`
#   application dependencies
#
# *_enabled vars denote whether the application is enabled or not. Unlike
#   *_managed it disables the application when `*_enabled: false`

service_port:
  nginx_proxy_http: "{{ (nginx_proxy_manager_enabled | default(false)) | ternary('9080', '80') }}"

###
### Server connection configuration
###
# Don't keep passwords in plain text, encrypt them. One option would be:
#   ansible-vault encrypt_string -J PASSWORD_PLACEHOLDER
ansible_user: "{{ lookup('env', 'ANSIBLE_USER') }}"
ansible_password: "{{ lookup('env', 'ANSIBLE_USER_PASS') }}"
ansible_become_password: "{{ lookup('env', 'ANSIBLE_USER_PASS') }}"

#################### {{ ROLES_CONF_TS4LE64m91 }} ####################


################
###   BASE   ###
################

# ===============
#       AGE
# ===============
# VERSIONS: https://github.com/FiloSottile/age/releases
# -----
age_managed: true
age_version:    # Leave blank to leverage bookshelf configuration

# =====================
#       BASH-SANE
# =====================
bash_sane_managed: true
bash_sane_users:    # <- Existing users to use bash set settings
  - "{{ ansible_user_id }}"

# ================
#       BASH
# ================
bash_managed: true
bash_completion: true
bash_users:   # <- Existing users to use bash by default
  - "{{ ansible_user_id }}"

# ========================
#       DOCKER-CLEAN
# ========================
docker_clean_managed: "{{ docker_managed | default(false) }}"   # <- When docker installed
docker_clean_logrotate_keep_count: 7
docker_clean_prune_images: true     # <- Weekly prune unused images

# ==========
#   DOCKER
# ==========
docker_managed: true
docker_users:   # <- Users to be added to docker group
  - "{{ ansible_user_id }}"

# =========
#   ENVAR
# =========
envar_managed: true
envar_users:  # <- Existing users to have access to envar
  - "{{ ansible_user_id }}"
  - root

# ===============
#       FZF
# ===============
# VERSIONS: https://github.com/junegunn/fzf/releases
# -----
fzf_managed: true
fzf_version:    # Leave blank to leverage bookshelf configuration
fzf_users:      # <- Existing users to have fzf integrated
  - "{{ ansible_user | default(ansible_user_id) }}"
  - root

# =======
#   GIT
# =======
git_managed: true
git_extraconf:
  - owner: "{{ ansible_user_id }}"
    source: gitconfig.extra.ini.j2
    # Optional variables, can be addressed in the template via 'conf' map in case of template source
    user_name: Foo
    user_email: foo@bar.baz
  # - owner: another-user
  #   source: "{{ playbook_dir }}/resources/git/extra.ini"  # <- Handled as file due to not '*.j2'
  #   # No variables, as it's not a template
  # # ...

# ===========
#   PS1-GIT
# ===========
ps1_git_managed: true
ps1_git_users:  # <- Existing users to have this PS1
  - "{{ ansible_user_id }}"
  - root

# =========
#   SNAPD
# =========
snapd_managed: "{{ factum_os_like in ['ubuntu'] }}"  # <- Only supported by Ubuntu like

# ============================
#       TAILSCALE-CLIENT
# ============================
tailscale_client_managed: true

# ==============
#      TMUX
# ==============
tmux_managed: true
tmux_sane_users:   # <- Existing users to source my preferred configuration
  - "{{ ansible_user_id }}"

# ===============
#      TMUXP
# ===============
tmuxp_managed: "{{ factum_os_family not in ['alpine'] }}"   # <- Not supported by Alpine
tmuxp_conf:
  - owner: "{{ ansible_user_id }}"
    conf:
      - source: sensors.yaml.j2
        name: sensors
        # Optional variables, can be addressed in the template via 'conf' map in case of template source
        session_name: Sensors
        window_name: sensors
      - source: triple.yaml.j2
        name: triple
        pane3_start_dir: ~/tmp
  #     - source: "{{ playbook_dir }}/resources/tmuxp/demo1.yaml"   # <- Handled as file due to not '*.j2'
  #       name: demo1
  #       # No variables, as it's not a template
  # - owner: # ...
  #   # ...

# ====================
#       TOOLBELT
# ====================
# Contains very basic and often needed tools that for most often usage don't
# require any additional configuration. Some of the tools are categorized and
# the categories can be used to install the whole set of underlying tools.
# -----
# * editors:      nano, neovim, vim
# * downloaders:  curl, wget
# * viewers:      bat, glow
# * htop, jq, sensors, skate, speedtest, tar, wishlist
# -----
toolbelt_managed: true
toolbelt_pick:      # <- Install only a fraction. Leave empty to install all
  # - nano            # <- nano will be installed
  # - downloaders     # <- All downloaders will be installed
  # - tar             # <- tar will be installed
toolbelt_exclude:   # <- Opposed to toolbelt_pick, higher priority than toolbelt_pick
  # - wget            # <- In conjunction with toolbelt_pick above, only curl will be installed
  # - editors         # <- Dispite toolbelt_pick above, nano will not be installed

# ========================
#       VIRT-MANAGER
# ========================
virt_manager_managed: "{{ factum_os_family in ['debian'] }}"  # <- Only Debian family is supported
virt_manager_users:   # <- Existing users to be added to libvirt group
  - "{{ ansible_user_id }}"



###################
###   SERVICE   ###
###################

# ===================
#       ADGUARD
# ===================
# VERSIONS:
#   * https://hub.docker.com/r/adguard/adguardhome/tags
#   * => See tailscale role versions
# -----
adguard_managed: "{{ factum_os_like not in ['ubuntu'] }}"   # <- All hosts but Ubuntu
adguard_enabled: true
adguard_version:        # Leave blank to leverage bookshelf configuration
adguard_compose_dir:    # Unless you know ..., leave blank to leverage bookshelf configuration
adguard_owner: "{{ ansible_user_id }}"
adguard_conf_dir: ~/conf/adguard
adguard_service_name: adguard
adguard_hostname: "{{ adguard_service_name }}"
adguard_vhost: "{{ adguard_service_name }}.domain.local"
adguard_web_ui_port:    # Leave blank to leverage bookshelf configuration
adguard_init_ui_port:   # Leave blank to leverage bookshelf configuration
adguard_tz: "{{ ansible_date_time.tz | default('UTC') }}"
# Optional extra env vars, will affect both adguard and tailscale.
adguard_extra_env: |    # "{{ lookup('template', playbook_dir + '/resources/adguard.env.j2') }}"
  # Useless test data
  FOO1=bar1
  FOO2=bar2
# ----------
# The following settings configure Adguard to run as a part of tailnet. This
# allows to configure adguard for a tailnet DNS server under
# https://tailscale.com/admin/dns -> Nameservers
#
# IMPORTANT 1: See IMPORTANTs in tailscale service description
#
# NOTE 1: Local network is not accessible within tailnet, which means that if i
# create an adguard DNS rewrite for 'my-site.local' to '192.168.0.20', the site
# will not be reachable in the tailnet. SOLUTION: deploy another tailscale
# service with "advertised routes" (https://tailscale.com/kb/1019/subnets)
adguard_tailscaled: false
adguard_tailscale_version:    # Leave blank to leverage bookshelf configuration
adguard_tailscale_ts_hostname: "{{ adguard_service_name }}-tailscale"
adguard_tailscale_auth_key:

# ==========================
#       AUDIOBOOKSHELF
# ==========================
# VERSIONS:
#   * https://hub.docker.com/r/advplyr/audiobookshelf/tags
#   * => See tailscale role versions
# -----
audiobookshelf_managed: true
audiobookshelf_enabled: true
audiobookshelf_version:       # Leave blank to leverage bookshelf configuration
audiobookshelf_compose_dir:   # Unless you know ..., leave blank to leverage bookshelf configuration
audiobookshelf_owner: root    # <- Who runs the container
audiobookshelf_user: "{{ ansible_user_id }}"    # <- The in-container user and data filesystem owner
audiobookshelf_conf_dir: "{{ audiobookshelf_owner_home }}/conf/audiobookshelf"
audiobookshelf_data_dir: "{{ audiobookshelf_user_home }}/share/Audiobooks"   # (REQUIRED)
audiobookshelf_service_name: audiobookshelf
audiobookshelf_hostname: "{{ audiobookshelf_service_name }}"
audiobookshelf_vhost: "{{ audiobookshelf_service_name }}.domain.local"
audiobookshelf_web_ui_port:   # Leave blank to leverage bookshelf configuration
audiobookshelf_tz: "{{ ansible_date_time.tz | default('UTC') }}"
# Optional extra env vars, will affect both audiobookshelf and tailscale.
audiobookshelf_extra_env: |   # "{{ lookup('template', playbook_dir + '/resources/audiobookshelf.env.j2') }}"
  # Useless test data
  FOO1=bar1
  FOO2=bar2
# ----------
# The following settings configure Audiobookshelf to run as a part of tailnet
#
# IMPORTANT 1: See IMPORTANTs in tailscale service description
audiobookshelf_tailscaled: false
audiobookshelf_tailscale_version:   # Leave blank to leverage bookshelf configuration
# Hostname within tailnet
audiobookshelf_tailscale_ts_hostname: "{{ audiobookshelf_service_name }}-tailscale"
audiobookshelf_tailscale_auth_key:

# =======================
#       CODE-SERVER
# =======================
# VERSIONS: https://github.com/coder/code-server/releases
# -----
code_server_managed: "{{ factum_os_family not in ['alpine'] }}"
code_server_version:      # Leave blank to leverage bookshelf configuration
code_server_owner: "{{ ansible_user_id }}"
code_server_web_ui_port:  # Leave blank to leverage bookshelf configuration
code_server_extensions:   # <- List of extension
  # - editorconfig.editorconfig
  # - mads-hartmann.bash-ide-vscode
  # - timonwong.shellcheck
  # - foxundermoon.shell-format
  # - redhat.ansible
code_server_pass: changeme
# If defined, takes precedence over 'code_server_pass'.
# Generate with (replace PASS with your value):
#   printf -- '%s' 'PASS' | docker container run -i --rm alpine /bin/sh -c 'apk add --update --no-cache argon2 openssl && argon2 "$(openssl rand -base64 8)" -e'
# Changeme123
code_server_hashed_pass: "$argon2i$v=19$m=4096,t=3,p=1$WDlYSWhzL2RTUWc9$+KWVsLyUUfaCb4AcvkoCK52uo3z608fQ/ED1mvsCysE"
code_server_custom_conf:    # "{{ lookup('template', playbook_dir + '/resources/code-server.config.yaml.j2') }}"
code_server_user_conf:      # "{{ lookup('template', 'sane.json.j2') }}"

# =======================
#       FILEBROWSER
# =======================
# VERSIONS:
#   * https://hub.docker.com/r/filebrowser/filebrowser/tags?name=-s6
#   * => See tailscale role versions
# -----
filebrowser_managed: true
filebrowser_enabled: true
filebrowser_version:        # Leave blank to leverage bookshelf configuration
filebrowser_compose_dir:    # Unless you know ..., leave blank to leverage bookshelf configuration
filebrowser_owner: root    # <- Who runs the container
filebrowser_user: "{{ ansible_user_id }}"   # <- The in-container user and data filesystem owner
filebrowser_conf_dir: "{{ filebrowser_owner_home }}/conf/filebrowser"
filebrowser_data_dir: "{{ filebrowser_user_home }}"   # (REQUIRED). Ex.: "{{ filebrowser_user_home }}/Filebrowser"
filebrowser_service_name: filebrowser
filebrowser_hostname: "{{ filebrowser_service_name }}"
filebrowser_vhost: "{{ filebrowser_service_name }}.domain.local"
filebrowser_web_ui_port:    # Leave blank to leverage bookshelf configuration
filebrowser_tz: "{{ ansible_date_time.tz | default('UTC') }}"
filebrowser_extra_env: |    # "{{ lookup('template', playbook_dir + '/resources/filebrowser.env.j2') }}"
  FOO1=bar1
  FOO2=bar2
# ----------
# The following settings configure FileBrowser to run as a part of tailnet
#
# IMPORTANT 1: See IMPORTANTs in tailscale service description
filebrowser_tailscaled: false
filebrowser_tailscale_version:    # Leave blank to leverage bookshelf configuration
# Hostname within tailnet
filebrowser_tailscale_ts_hostname: "{{ filebrowser_service_name }}-tailscale"
filebrowser_tailscale_auth_key:

# ==================
#       GOTIFY
# ==================
# VERSIONS: https://hub.docker.com/r/gotify/server/tags
# -----
gotify_managed: true
gotify_enabled: true
gotify_version:       # Leave blank to leverage bookshelf configuration
gotify_compose_dir:   # Unless you know ..., leave blank to leverage bookshelf configuration
gotify_owner: "{{ ansible_user_id }}"
gotify_conf_dir: ~/conf/gotify
gotify_service_name: gotify
gotify_hostname: "{{ gotify_service_name }}"
gotify_vhost: "{{ gotify_service_name }}.domain.local"
gotify_web_ui_port:   # Leave blank to leverage bookshelf configuration
gotify_tz: "{{ ansible_date_time.tz | default('UTC') }}"

# ====================
#       HEIMDALL
# ====================
# VERSIONS: https://hub.docker.com/r/linuxserver/heimdall/tags
# -----
heimdall_managed: true
heimdall_enabled: true
heimdall_version:       # Leave blank to leverage bookshelf configuration
heimdall_compose_dir:   # Unless you know ..., leave blank to leverage bookshelf configuration
heimdall_owner: "{{ ansible_user_id }}"
heimdall_conf_dir: ~/conf/heimdall
heimdall_service_name: heimdall
heimdall_hostname: "{{ heimdall_service_name }}"
heimdall_vhost: "{{ heimdall_service_name }}.domain.local"
heimdall_web_ui_port:   # Leave blank to leverage bookshelf configuration
heimdall_tz: "{{ ansible_date_time.tz | default('UTC') }}"

# ====================
#       JELLYFIN
# ====================
# VERSIONS:
#   * https://hub.docker.com/r/linuxserver/jellyfin/tags
#   * => See tailscale role versions
# -----
jellyfin_managed: true
jellyfin_enabled: true
jellyfin_version:       # Leave blank to leverage bookshelf configuration
jellyfin_compose_dir:   # Unless you know ..., leave blank to leverage bookshelf configuration
jellyfin_owner: root                    # <- Who runs the container
jellyfin_user: "{{ ansible_user_id }}"  # <- The in-container user and data filesystem owner
jellyfin_conf_dir: "{{ jellyfin_owner_home }}/conf/jellyfin"
jellyfin_data_dir: "{{ jellyfin_user_home }}/share/Media"   # (REQUIRED). Ex.: "{{ jellyfin_user_home }}/share/Media"
jellyfin_service_name: jellyfin
jellyfin_hostname: "{{ jellyfin_service_name }}"
jellyfin_vhost: "{{ jellyfin_service_name }}.domain.local"
jellyfin_web_ui_port:   # Leave blank to leverage bookshelf configuration
jellyfin_tz: "{{ ansible_date_time.tz | default('UTC') }}"
jellyfin_extra_env: |   # "{{ lookup('template', playbook_dir + '/resources/jellyfin.env.j2') }}"
  FOO1=bar1
  FOO2=bar2
# ----------
# The following settings configure Jellyfin to run as a part of tailnet
#
# IMPORTANT 1: See IMPORTANTs in tailscale service description
jellyfin_tailscaled: false
jellyfin_tailscale_version:    # Leave blank to leverage bookshelf configuration
# Hostname within tailnet
jellyfin_tailscale_ts_hostname: "{{ jellyfin_service_name }}-tailscale"
jellyfin_tailscale_auth_key:

# =========================
#       JOPLIN-SERVER
# =========================
# VERSIONS:
#   * https://hub.docker.com/r/joplin/server/tags
#   * https://hub.docker.com/_/postgres/tags?name=alpine
# -----
joplin_server_managed: true
joplin_server_enabled: true
joplin_server_version:              # Leave blank to leverage bookshelf configuration
joplin_server_postgres_version:     # Leave blank to leverage bookshelf configuration
joplin_server_compose_dir:          # Unless you know ..., leave blank to leverage bookshelf configuration
joplin_server_owner: "{{ ansible_user_id }}"
joplin_server_conf_dir: ~/conf/joplin-server
joplin_server_service_name: joplin-server
joplin_server_hostname: "{{ joplin_server_service_name }}"
joplin_server_vhost: "{{ joplin_server_service_name }}.domain.local"
joplin_server_web_ui_port:          # Leave blank to leverage bookshelf configuration
# Joplin base url. Ex.:
#   https://{{ joplin_server_vhost }}
#   http://{{ ansible_default_ipv4.address }}:{{ joplin_server_web_ui_port | default(bookshelf_const_port.joplin_server.web_ui, true) }}
joplin_server_base_url: http://{{ ansible_default_ipv4.address }}:{{ joplin_server_web_ui_port | default(bookshelf_const_port.joplin_server.web_ui, true) }}
joplin_server_db_pass: changeme
joplin_server_tz: "{{ ansible_date_time.tz | default('UTC') }}"

# =====================
#       NAVIDROME
# =====================
# VERSIONS: https://hub.docker.com/r/deluan/navidrome/tags
# -----
navidrome_managed: true
navidrome_enabled: true
navidrome_version:        # Leave blank to leverage bookshelf configuration
navidrome_compose_dir:    # Unless you know ..., leave blank to leverage bookshelf configuration
navidrome_owner: root                       # <- Who runs the container
navidrome_user: "{{ ansible_user_id }}"     # <- The in-container user and data filesystem owner
navidrome_conf_dir: "{{ navidrome_owner_home }}/conf/navidrome"
navidrome_data_dir: "{{ navidrome_user_home }}/Music"   # (REQUIRED). Ex.: "{{ navidrome_user_home }}/Music"
navidrome_service_name: navidrome
navidrome_hostname: "{{ navidrome_service_name }}"
navidrome_vhost: "{{ navidrome_service_name }}.domain.local"
navidrome_web_ui_port:    # Leave blank to leverage bookshelf configuration
navidrome_tz: "{{ ansible_date_time.tz | default('UTC') }}"
# Optional extra env vars, will affect both navidrome and tailscale.
# https://www.navidrome.org/docs/usage/configuration-options/#available-options
navidrome_extra_env: |    # "{{ lookup('template', playbook_dir + '/resources/navidrome.env.j2') }}"
  FOO1=bar1
  FOO2=bar2
# ----------
# The following settings configure Navidrome to run as a part of tailnet
#
# IMPORTANT 1: See IMPORTANTs in tailscale service description
navidrome_tailscaled: false
navidrome_tailscale_version:    # Leave blank to leverage bookshelf configuration
# Hostname within tailnet
navidrome_tailscale_ts_hostname: "{{ navidrome_service_name }}-tailscale"
navidrome_tailscale_auth_key:

# ==================
#       METUBE
# ==================
# VERSIONS: https://github.com/alexta69/metube/pkgs/container/metube
# -----
metube_managed: true
metube_enabled: true
metube_version:       # Leave blank to leverage bookshelf configuration
metube_compose_dir:   # Unless you know ..., leave blank to leverage bookshelf configuration
metube_owner: root       # <- Who runs the container
metube_user: "{{ ansible_user_id }}"   # <- The in-container user and data filesystem owner
metube_conf_dir: "{{ metube_owner_home }}/conf/metube"
metube_data_dir: "{{ metube_user_home }}/share/Metube"     # (REQUIRED). Ex.: "{{ metube_user_home }}/share/Metube"
metube_service_name: metube
metube_hostname: "{{ metube_service_name }}"
metube_vhost: "{{ metube_service_name }}.domain.local"
metube_web_ui_port:   # Leave blank to leverage bookshelf configuration
metube_tz: "{{ ansible_date_time.tz | default('UTC') }}"
# https://github.com/alexta69/metube?tab=readme-ov-file#configuration-via-environment-variables
metube_extra_env: |   # "{{ lookup('template', playbook_dir + '/resources/metube.env.j2') }}"
  FOO1=bar1
  FOO2=bar2

# =======================
#   NGINX-PROXY-MANAGER
# =======================
# VERSIONS: https://hub.docker.com/r/jc21/nginx-proxy-manager/tags
# -----
nginx_proxy_manager_managed: true
nginx_proxy_manager_enabled: true
nginx_proxy_manager_version:        # Leave blank to leverage bookshelf configuration
nginx_proxy_manager_compose_dir:    # Unless you know ..., leave blank to leverage bookshelf configuration
nginx_proxy_manager_owner: "{{ ansible_user_id }}"
nginx_proxy_manager_conf_dir: ~/conf/nginx-proxy-manager
nginx_proxy_manager_service_name: nginx-proxy-manager
nginx_proxy_manager_hostname: "{{ nginx_proxy_manager_service_name }}"
nginx_proxy_manager_vhost: "{{ nginx_proxy_manager_service_name }}.domain.local"
nginx_proxy_manager_extra_env: |    # "{{ lookup('template', playbook_dir + '/resources/nginx-proxy-manager.env.j2') }}"
  FOO1=bar1
  FOO2=bar2

# ===============
#   NGINX-PROXY
# ===============
# Versions:
# * https://hub.docker.com/r/jwilder/nginx-proxy/tags?name=alpine
# Exposes:
# * nxinx_proxy_net - proxy network name
# -----
nginx_proxy_managed: true
nginx_proxy_enabled: true
nginx_proxy_version:        # Leave blank to leverage bookshelf configuration
nginx_proxy_compose_dir:    # Unless you know ..., leave blank to leverage bookshelf configuration
nginx_proxy_owner: "{{ ansible_user_id }}"
nginx_proxy_service_name: nginx-proxy
nginx_proxy_hostname: "{{ nginx_proxy_service_name }}"
nginx_proxy_http_port: "{{ service_port.nginx_proxy_http }}"     # Ex.: '80', no HTTP when empty
nginx_proxy_https_port:     # Ex.: '443', no HTTPS when empty
nginx_proxy_certs_dir:      # Path to certs on the managed machine. Works paired with HTTPS

# ====================
#       OLIVETIN
# ====================
olivetin_managed: true
olivetin_enabled: true
olivetin_version:       # Leave blank to leverage bookshelf configuration
olivetin_compose_dir:   # Unless you know ..., leave blank to leverage bookshelf configuration
olivetin_owner: "{{ ansible_user_id }}"
olivetin_conf_dir: ~/conf/olivetin
olivetin_service_name: olivetin
olivetin_hostname: "{{ olivetin_service_name }}"
olivetin_vhost: "{{ olivetin_service_name }}.domain.local"
olivetin_web_ui_port:   # Leave blank to leverage bookshelf configuration
olivetin_scripts:
  - text: "{{ lookup('file', 'sample.sh') }}"
    name: sample.sh
olivetin_volumes:
  - '~:/app/home:ro'
olivetin_config: "{{ lookup('file', 'config.yaml') }}"

# ===========================
#       PORTAINER-AGENT
# ===========================
# Versions:
# * https://hub.docker.com/r/portainer/agent/tags?name=alpine
# -----
portainer_agent_managed: true
portainer_agent_enabled: true
portainer_agent_version:        # Leave blank to leverage bookshelf configuration
portainer_agent_compose_dir:    # Unless you know ..., leave blank to leverage bookshelf configuration
portainer_agent_owner: "{{ ansible_user_id }}"
portainer_agent_service_name: portainer-agent
portainer_agent_hostname: "{{ portainer_service_name }}"
portainer_agent_host_management: true
portainer_agent_tcp_port: 9002  # Leave blank to leverage bookshelf configuration

# =====================
#       PORTAINER
# =====================
# Versions:
# * https://hub.docker.com/r/portainer/portainer-ce/tags?name=alpine
# -----
portainer_managed: true
portainer_enabled: true
portainer_version:        # Leave blank to leverage bookshelf configuration
portainer_compose_dir:    # Unless you know ..., leave blank to leverage bookshelf configuration
portainer_owner: "{{ ansible_user_id }}"
portainer_conf_dir: ~/conf/portainer
portainer_service_name: portainer
portainer_hostname: "{{ portainer_service_name }}"
portainer_vhost: "{{ portainer_service_name }}.domain.local"
portainer_web_ui_port:    # Leave blank to leverage bookshelf configuration
# Publish ssh tunnel server port
portainer_agent_ready: true

# =======================
#       QBITTORRENT
# =======================
# Free and reliable P2P Bittorrent client
#   https://www.qbittorrent.org/
#   https://hub.docker.com/r/linuxserver/qbittorrent
# -----
# Versions:
# * https://hub.docker.com/r/linuxserver/qbittorrent/tags?name=-ls
# * https://github.com/VueTorrent/VueTorrent/pkgs/container/vuetorrent-lsio-mod/versions
# -----
# NOTE 1: Temporary password for the admin user will be printed to the container
# log on startup
#
# NOTE 2: Switch to alternative UI
#   Settings > WebUI > check Use alternative WebUI, Files location: /vuetorrent
qbittorrent_managed: true
qbittorrent_enabled: true
qbittorrent_version:              # Leave blank to leverage bookshelf configuration
qbittorrent_vuetorrent_version:   # Leave blank to leverage bookshelf configuration
qbittorrent_compose_dir:          # Unless you know ..., leave blank to leverage bookshelf configuration
qbittorrent_owner: root       # <- Who runs the container
qbittorrent_user: "{{ ansible_user_id }}"   # <- The in-container user and data filesystem owner
qbittorrent_conf_dir: "{{ qbittorrent_owner_home }}/conf/qbittorrent"
qbittorrent_data_dir: "{{ qbittorrent_user_home }}/share/Torrent"     # (REQUIRED). Ex.: "{{ qbittorrent_user_home }}/share/Torrent"
qbittorrent_service_name: qbittorrent
qbittorrent_hostname: "{{ qbittorrent_service_name }}"
qbittorrent_vhost: "{{ qbittorrent_service_name }}.domain.local"
qbittorrent_web_ui_port:          # Leave blank to leverage bookshelf configuration
qbittorrent_tz: "{{ ansible_date_time.tz | default('UTC') }}"
# Optional. May require additional setting variables. Will be available in the container in
#   /scripts/downloaded.sh (0700)
#   /scripts/downloaded.secret.sh (0600)
# Configure in qBittorrent UI -> Settings -> Downloads -> External ... on finished
# For demo scripts see:
#   templates/*-push.*
qbittorrent_downloaded_script: "{{ lookup('template', 'gotify-push.sh.j2') }}"
qbittorrent_gotify_server: https://gotify.home
# Optional, can be used in conjunction with qbittorrent_downloaded_script to keep
# secrets separately from the downloaded event script.
# Will only be used when qbittorrent_downloaded_script is set
qbittorrent_downloaded_secret: "{{ lookup('template', 'gotify-push.secret.sh.j2') }}"
qbittorrent_gotify_token: changeme
# Optional extra env vars
qbittorrent_extra_env: |          # "{{ lookup('template', playbook_dir + '/resources/qbittorrent.env.j2') }}"
  FOO1=bar1
  FOO2=bar2

# =================
#       SAMBA
# =================
# Versions:
# * https://hub.docker.com/r/crazymax/samba/tags
# -----
samba_managed: true
samba_enabled: true
samba_version:        # Leave blank to leverage bookshelf configuration
samba_compose_dir:    # Unless you know ..., leave blank to leverage bookshelf configuration
samba_owner: "{{ ansible_user_id }}"
samba_shares_dir: ~/Samba    # (REQUIRED) Shares root directory
samba_service_name: samba
samba_hostname: "{{ samba_service_name }}"
samba_tz: "{{ ansible_date_time.tz | default('UTC') }}"
# Optional path to extra configuration .env.j2 file
# Ex.: "{{ playbook_dir }}/resources/samba/extra.env.j2"
samba_extra_envfile:

# =====================
#       SYNCTHING
# =====================
# Versions:
# * https://hub.docker.com/r/linuxserver/syncthing/tags?name=-ls
# -----
syncthing_managed: true
syncthing_enabled: true
syncthing_version:              # Leave blank to leverage bookshelf configuration
syncthing_compose_dir:          # Unless you know ..., leave blank to leverage bookshelf configuration
syncthing_owner: root  # <- Who runs the container
syncthing_user: "{{ ansible_user_id }}"   # <- The in-container user and data filesystem owner
syncthing_conf_dir: "{{ syncthing_owner_home }}/conf/syncthing"
syncthing_data_dir: "{{ syncthing_user_home }}/share"   # (REQUIRED). Ex.: "{{ syncthing_user_home }}/share"
syncthing_service_name: syncthing
syncthing_hostname: "{{ syncthing_service_name }}"
syncthing_vhost: "{{ syncthing_service_name }}.domain.local"
syncthing_web_ui_port:          # Leave blank to leverage bookshelf configuration
syncthing_tz: "{{ ansible_date_time.tz | default('UTC') }}"
syncthing_extra_env: |          # "{{ lookup('template', playbook_dir + '/resources/syncthing.env.j2') }}"
  FOO1=bar1
  FOO2=bar2
# ----------
# The following settings configure Syncthing to run as a part of tailnet
#
# IMPORTANT 1: See IMPORTANTs in tailscale service description
syncthing_tailscaled: false
syncthing_tailscale_version:    # Leave blank to leverage bookshelf configuration
# Hostname within tailnet
syncthing_tailscale_ts_hostname: "{{ syncthing_service_name }}-tailscale"
syncthing_tailscale_auth_key:

# =====================
#       TAILSCALE
# =====================
# Versions:
# * https://hub.docker.com/r/tailscale/tailscale/tags
# -----
# IMPORTANT 1: Auth key is required for initial container run:
# https://tailscale.com/admin/settings/keys -> 'Generate auth key...'
#   -> generate single time or reusable
#
# IMPORTANT 2: After deployment https://tailscale.com/admin/machines -> 3 dots
# next to the machine -> Disable key expiry (to avoid re-login to tailscale)
#
# IMPORTANT 3: With changed routes or exit node params service requires a valid
# auth key, i.e. if it's one-timer new one must be provided
#
# NOTE 1: The service is useless unless it's configured for exit node or subnet
# router. Both need to be confirmed in the machines admin
tailscale_managed: false
tailscale_enabled: false
tailscale_version:          # Leave blank to leverage bookshelf configuration
tailscale_compose_dir:      # Unless you know ..., leave blank to leverage bookshelf configuration
tailscale_owner: "{{ ansible_user_id }}"
tailscale_conf_dir: ~/conf/tailscale
tailscale_service_name: tailscale
tailscale_hostname: "{{ tailscale_service_name }}"
tailscale_auth_key:
# Ex.: '192.168.0.0/24,192.168.2.0/24'
tailscale_routes:
tailscale_exit_node: false  # Advertise exit node
tailscale_extra_env: |      # "{{ lookup('file', playbook_dir + '/resources/tailscale.env') }}"
  FOO1=bar1
  FOO2=bar2

# ====================
#       TWINGATE
# ====================
# Versions:
# * https://hub.docker.com/r/twingate/connector/tags
# -----
twingate_managed: false
twingate_enabled: false
twingate_version:         # Leave blank to leverage bookshelf configuration
twingate_compose_dir:     # Unless you know ..., leave blank to leverage bookshelf configuration
twingate_owner: "{{ ansible_user_id }}"
twingate_service_name: twingate
twingate_hostname: "{{ twingate_service_name }}"
twingate_tenant_name:     # Your twingate network name. Required
# https://<tenant>.twingate.com/networks/overview -> 'Deploy ... Connector'
#   -> 'Docker' -> 'Generate Tokens'
twingate_access_token:    # Required
twingate_refresh_token:   # Required
twingate_extra_env: |     # "{{ lookup('file', playbook_dir + '/resources/twingate.env') }}"
  FOO1=bar1
  FOO2=bar2

# =======================
#       VAULTWARDEN
# =======================
# The community driven password manager.
#   https://www.vaultwarden.net/
# -----
# Versions:
# * https://hub.docker.com/r/vaultwarden/server/tags?name=alpine
# Options description:
# * https://github.com/dani-garcia/vaultwarden/blob/main/.env.template
# -----
vaultwarden_managed: true
vaultwarden_enabled: true
vaultwarden_version:        # Leave blank to leverage bookshelf configuration
vaultwarden_compose_dir:    # Unless you know ..., leave blank to leverage bookshelf configuration
vaultwarden_owner: "{{ ansible_user_id }}"
vaultwarden_conf_dir: ~/conf/vaultwarden
vaultwarden_service_name: vaultwarden
vaultwarden_hostname: "{{ vaultwarden_service_name }}"
vaultwarden_vhost: "{{ vaultwarden_service_name }}.domain.local"
# Required with https via reverse proxy, vaultwarden needs to know it's https
# to work properly with attachments.
# https://github.com/dani-garcia/vaultwarden/wiki/Using-Docker-Compose
# Ex.: https://{{ vaultwarden_vhost }}
vaultwarden_vdomain: https://{{ vaultwarden_vhost }}
# Access token for http(s)://VAULTWARDEN_HOST/admin
# Generate with:
#   docker container run -it --rm vaultwarden/server:latest /vaultwarden hash
vaultwarden_admin_token_hash:
vaultwarden_web_ui_port:    # Leave blank to leverage bookshelf configuration
vaultwarden_tz: "{{ ansible_date_time.tz | default('UTC') }}"
vaultwarden_extra_env: |    # "{{ lookup('file', playbook_dir + '/resources/vaultwarden.env') }}"
  FOO1=bar1
  FOO2=bar2

# ===================
#       WG-EASY
# ===================
# The easiest way to run WireGuard VPN + Web-based Admin UI.
#   https://github.com/wg-easy/wg-easy
# -----
# Versions:
# * https://github.com/wg-easy/wg-easy/pkgs/container/wg-easy/versions?filters%5Bversion_type%5D=tagged
# Options description:
# * https://github.com/wg-easy/wg-easy/tree/production?tab=readme-ov-file#options
# * https://github.com/wg-easy/wg-easy/blob/production/How_to_generate_an_bcrypt_hash.md
# -----
wg_easy_managed: true
wg_easy_enabled: true
wg_easy_version:        # Leave blank to leverage bookshelf configuration
wg_easy_compose_dir:    # Unless you know ..., leave blank to leverage bookshelf configuration
wg_easy_owner: "{{ ansible_user_id }}"
wg_easy_conf_dir: ~/conf/wg-easy
wg_easy_service_name: wg-easy
wg_easy_hostname: "{{ wg_easy_service_name }}"
wg_easy_vhost: "{{ wg_easy_service_name }}.domain.local"
wg_easy_web_ui_port:    # Leave blank to leverage bookshelf configuration
wg_easy_udp_port: 51820 # Must match the UDP port configured in UI
wg_easy_insecure: 'true'  # Allow login via plain http
# Optional extra env vars
wg_easy_extra_env:      # "{{ lookup('template', playbook_dir + '/resources/wg-easy.env.j2') }}"



###################
###   DESKTOP   ###
###################

# ============
#   AUDACITY
# ============
audacity_managed: false

# =================
#       BRAVE
# =================
brave_managed: false

# ==================
#       CHROME
# ==================
chrome_managed: false

# =================
#       COPYQ
# =================
copyq_managed: false
# 'pm' or 'flatpak'. With non-ubuntu always forced to 'flatpak'
copyq_install_method: pm
copyq_starters:         # <- Existing users to have copyq autostarted
  # - "{{ ansible_user_id }}"

# ===================
#       DBEAVER
# ===================
dbeaver_managed: false
# 'snap' or 'flatpak'. With non-ubuntu always forced to 'flatpak'
dbeaver_install_method: flatpak

# =====================
#       DOUBLECMD
# =====================
# Cross platform open source file manager with two panels side by side.
#   https://doublecmd.sourceforge.io/
# -----
doublecmd_managed: false    # "{{ factum_os_family in ['debian'] }}"  # <- Only supported by Debian family
doublecmd_ui_lib: gtk       # <- 'gtk' for Gnome or 'qt' for KDE
doublecmd_starters:         # <- Existing users to have doublecmd autostarted
  # - "{{ ansible_user_id }}"

# ===========
#   FLATPAK
# ===========
flatpak_managed: false
flatpak_repos:    # <- Currently only the ones in the example are supported
  # - flathub

# ================
#       GIMP
# ================
gimp_managed: false
# Supported values in prefered order (due to GUI oriented usage):
# * flatpak   # <- Forced for non-Ubuntu-like
# * snap
gimp_install_method: flatpak

# ======================
#       INPUT-LEAP
# ======================
input_leap_managed: false
input_leap_starters:  # <- Existing users to have InputLeap autostarted
  # - "{{ ansible_user_id }}"

# =========================
#       INTELLIJ-IDEA
# =========================
intellij_idea_managed: false
# Ultimate edition, unless community
intellij_idea_ultimate: false

# ===========================
#       JELLYFIN-PLAYER
# ===========================
# Desktop client for Jellyfin media server.
#   https://github.com/jellyfin/jellyfin-media-player
# -----
jellyfin_player_managed: false
jellyfin_player_starters:   # <- Existing users to have jellyfin player autostarted
  # - "{{ ansible_user_id }}"

# ==========================
#       JOPLIN-DESKTOP
# ==========================
joplin_desktop_managed: false
# Supported values in prefered order (due newer versions in snap):
# * snap
# * flatpak   # <- Forced for non-Ubuntu-like
joplin_desktop_install_method: snap

# ====================
#       KDENLIVE
# ====================
kdenlive_managed: false
# 'snap' or 'flatpak'
kdenlive_install_method: snap

# ======================
#       MKVTOOLNIX
# ======================
mkvtoolnix_managed: false

# ====================
#       NXPLAYER
# ====================
nxplayer_managed: false

# ======================
#       OBS-STUDIO
# ======================
obs_studio_managed: false

# =================
#       OPERA
# =================
opera_managed: false

# ============
#   PHPSTORM
# ============
phpstorm_managed: false

# =================
#       PINTA
# =================
pinta_managed: false
# 'snap' or 'flatpak'
pinta_install_method: flatpak

# ===================
#       POSTMAN
# ===================
postman_managed: false
# Supported values in prefered order (due to GUI oriented usage):
# * flatpak   # <- Forced for non-Ubuntu-like
# * snap
postman_install_method: flatpak

# ===========
#   SUBLIME
# ===========
sublime_managed: false
sublime_merge: false
# Supported values in prefered order (due to available CLI interface):
# * pm    # <- Forced for non-Ubuntu-like
# * snap
sublime_install_method: pm

# =========
#   TEAMS
# =========
teams_managed: false
teams_starters:   # <- Existing users to have teams autostarted
  # - "{{ ansible_user_id }}"

# ====================
#       TELEGRAM
# ====================
telegram_managed: false
# Supported values in prefered order (due to GUI oriented usage):
# * flatpak   # <- Forced for non-Ubuntu-like
# * snap
telegram_install_method: flatpak
telegram_starters:         # <- Existing users to have telegram autostarted
  # - "{{ ansible_user_id }}"

# ======================
#       TERMINATOR
# ======================
terminator_managed: false

# =========
#   VIBER
# =========
viber_managed: false
viber_starters:   # <- Existing users to have viber autostarted
  # - "{{ ansible_user_id }}"

# =======
#   VLC
# =======
vlc_managed: false

# ==========
#   VSCODE
# ==========
vscode_managed: false
# Supported values in prefered order (due to available CLI interface):
# * snap
# * flatpak   # <- Forced for non-Ubuntu-like
vscode_install_method: snap
vscode_extensions:      # <- Per user extensions
  # - owner: "{{ ansible_user_id }}"  # <- Existing user. Must be unique
  #   extensions:
  #     - editorconfig.editorconfig
  #     - mads-hartmann.bash-ide-vscode
  #     - timonwong.shellcheck
  #     - foxundermoon.shell-format
  #     - redhat.ansible

# ===================
#       WHATSIE
# ===================
whatsie_managed: false
# Supported values in prefered order (due to GUI oriented usage):
# * flatpak   # <- Forced for non-Ubuntu-like
# * snap
whatsie_install_method: flatpak
